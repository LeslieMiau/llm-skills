# Review — Antigravity (Reviewer)

## Review Summary
整体架构分层得当，数据与规则解耦的思路非常清晰，但在计算调度选型、性能预见性以及向量化/事件驱动双引擎的融合思路上存在严重的过早优化与潜在性能隐患，同时完全遗漏了海量数据加载与内存管理的设计。

## Dimension Reviews

### Architecture Soundness
数据模型标准化和市场规则拆分是整个设计的亮点。分层解耦做得很规范，尤其是将不同市场的业务逻辑收存在 MarketRuleProvider 以保护策略层。
问题：
在“跨引擎账户模型统一”上，方案追求向量化模式和事件驱动模式共享同一套底层账户状态。这实际上极大地违背了向量化回测引擎追求高性能规模化计算的初衷。如果要求向量化计算链路强行去派发、更新一套复杂的面向对象模式的业务实体（包含资金切分、每日冻结流水），其性能不仅无法发挥，甚至还会因此陷入状态同步的地狱。

### Technical Feasibility
数据格式选型 (Parquet + DuckDB) 贴合研究化场景的数据计算诉求。
问题：
1. **调度工具不匹配**：参数扫描（Parameter Sweep）在多市场/多策略下会产生海量高密度的并行计算任务。使用 Celery/RQ 主要面向分布式的独立 IO 型短任务，面对超大规模的 DataFrame 时由于序列化传输负担会彻底成为单点甚至整个集群的传输瓶颈。这类以数据分析和计算为核心的高并发图调度场景应当使用 Ray 或 Dask。
2. **纯 Python 事件模拟性能隐忧**：方案中提到“先用 Python 实现，再优化”。但因为全动态特性，如果采取完全的事件驱动（逐 Tick/逐分钟创建大量 Order，Fill，甚至 Event Object），仅 Python 的对象生成与垃圾回收就可以将几年全市场规模的回放拖慢至无法使用的程度，这点可能达不到 MVP 所承诺的“形成可用研究闭环”。初期就需要以扁平化的数组、结构体字典等形式精简模拟。

### Missed Risks
1. **内存泄漏与数据流转管控缺陷（Data Loader Strategy 失位）**：方案缺少如何面对 A 股+美股+港股数十年庞大的分钟线甚至未来 Tick 级别数据的管控方案。如果使用传统的 Python 全量读入方式（即使是 Parquet）回测极易轻易 OOM (Out Of Memory)。引擎应该内置 Out-of-Core/流式读取 或者提供类似数据分片加载 Chunk，甚至是共享内存跨进程读取的机制设计。
2. **撮合模型对细粒度真实交易的深度依赖**：虽然方案声称会包含 Level 2 的基于 Bar 成交量约束和滑点的摩擦支持。但若没有更高频度数据的支持和做市做空影响度的有效预定义，分钟线上的 VWAP / TWAP 或参与率限制撮合会极度失真，不能用于深度校验的模拟结论。

### Alternative Approaches
1. **统一的高性能分布式底座**：不使用 Celery 编排而改用 Ray，可以直接在 Pandas/Arrow 共享内存（Plasma）的基础上执行分布式回测和结果极速拼装。
2. **投研前台展示框架**：Phase 2 考虑采用 React + ECharts。考虑到用户群为量化分析师且需要“报告即代码”级别的极度灵活迭代需求，建议更换技术栈为 Streamlit 或 Dash，可以直接从 Python 生成交互数据和面板看板，免去繁重复杂的客户端和服务端接口分离开发与维护。

## Specific Suggestions

### Suggestion 1: 摒弃底层“账户状态机共享”，降级为统一上界“分析输出接口”
- **Priority**: high
- **Issue**: 向量化计算与逐笔事件追踪范式截然不同，硬生生合并账户和持仓对象的内部流转极有可能导致不可挽回的性能瓶颈。
- **Suggestion**: 两种引擎只需各自实现最合适自己范式的状态追踪计算方法（如向量化核心使用矩阵），**不再强求一致性的 Account 对象**；只要能够保证这两种引擎对外最终产生的 `BacktestResult` (包括统一格式的 trade fills、每日 positions 截面序列、统一资金 equity curve) 完全可以被同一套 Analytics & Reporting 解析与归因即可。
- **Rationale**: 如此做到了真正的高内聚低耦合：内核只为性能负责，分析端对引擎内部细节零感知。

### Suggestion 2: 使用 Ray/Dask 替代 Celery 应对超大规模计算
- **Priority**: medium
- **Issue**: Celery 的任务载荷限制不仅无法在全栈 Python 里最高效传输大规模数据流（存在严重的 Pickling 负担），也没办法轻易做同节点的进程级别内存零成本分享。
- **Suggestion**: 明确建议将“任务组件底座”修改至专门面向科研、强化学习计算及参数调优的 Ray (或 Dask)。
- **Rationale**: 这个修改直接决定了在后期跑 Parameter Grid Search 或是大量组合投资回测调度时能不能跨机器且无需沉重中间件的流畅工作。

### Suggestion 3: 补充明确的“海量数据流式载入/内存溢出管控”体系设计
- **Priority**: high
- **Issue**: 对回测内存生命周期的保障机制完全失位。面对巨大的多币种多标的横截面数据往往引发进程 OOM。
- **Suggestion**: 在 §5 数据加载范本补充：引擎应设定物理内存上限阈值，要求预加载模型能够基于日/月做 Chunking （分片懒加载或者 Out of core 分析）；或者在向量化环境要求明确通过 DuckDB/Polars 承载数据池化避免 Pandas IO。
- **Rationale**: 这是系统“可用性”和“稳定性”从玩具迈向生产工具的必要条件。

### Suggestion 4: 用 Streamlit 或 Dash 替换传统的分离式 Web 前后端搭建开发
- **Priority**: low
- **Issue**: 使用 React/Vue 做内部投研系统的重资产开发对初创或核心量化项目属于沉没成本高、性价比极低的基建行为。
- **Suggestion**: 用 Python 侧的自动数据展示流框架如 Streamlit 统一化图表搭建。可以极大消除接口维护沟通甚至联调精力。
- **Rationale**: 分析人员有直接根据中间态即席撰写组件的需求，Streamlit 可以将此赋权给宽客团队成员自身。

## ⚠️ Conflicts with Other Reviewers (if applicable)

**与 Claude 的冲突点：针对 Suggestion 3（关于跨引擎账户模型统一）**
Claude 认为在“向量化模式与事件驱动模式”的双核下，缺失让底层账户流转完全对流对齐是最大的失误，由此倡议要在 V2 方案下明确提出“两者是如何通过同一条账户 Fill -> Position -> Account 路径”进行融合的。
但是，**我提出强烈的反对（⚠️ conflict）**。强迫向量化使用带有丰富业务状态机的传统 OOP 流水账，是极其危险的去优化行为，等于彻底扼杀向量化的极速穿透优点。正确的设计不仅不该在核心引擎里合二为一这套机制，反而应在最内层就完全阻断业务实体的状态互通（分别做面向性能最好的孤岛设计）。真正应该被保证和“跨模式统一”的，并非流水处理的方式，而是它们在 `Task Run` 结束之后抛射给数据分析层的最后归因结算数据格式要求（即统一的标准 `BacktestResult` JSON / Table 格式）。
